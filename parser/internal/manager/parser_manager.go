package manager

import (
	"bufio"
	"context"
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"job_parser/configs"
	"job_parser/internal/domain/models"
	"job_parser/internal/inmemory_cache"
	"job_parser/internal/interfaces"

	"strconv"
	"strings"

	"sync"
	"time"
)

type ParserManager struct {
	parsers []interfaces.Parser
	config  *configs.Config
}

// –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –¥–ª—è –º—ç–Ω–µ–¥–∂–µ—Ä–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
func NewParserManager(config *configs.Config, parsers ...interfaces.Parser) *ParserManager {
	return &ParserManager{
		parsers: parsers,
		config:  config,
	}
}

// –ú–µ—Ç–æ–¥ –¥–ª—è –º—É–ª—å—Ç–∏-–ø–æ–∏—Å–∫–∞
func (pm *ParserManager) MultiSearch(scanner *bufio.Scanner, cash *inmemory_cache.InmemoryShardedCache) {
	fmt.Println("\nüåê –ú—É–ª—å—Ç–∏-–ø–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π")

	var params models.SearchParams

	fmt.Print("–í–≤–µ–¥–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: ")
	if scanner.Scan() {
		params.Text = strings.TrimSpace(scanner.Text())
	}

	fmt.Print("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ (max 50): ")
	if scanner.Scan() {
		countStr := strings.TrimSpace(scanner.Text())
		if countStr != "" {
			if count, err := strconv.Atoi(countStr); err == nil && count > 0 {
				params.PerPage = count
			}
		}
	}

	if params.PerPage == 0 {
		params.PerPage = 20
	}

	searchHash, _ := GenHashFromSearchParam(params) // ****!!!! –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—à–∏–±–∫—É
	fmt.Println("–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ö—ç—à:", searchHash)

	fmt.Println("‚è≥ –ò—â–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ –∫—ç—à–µ...")
	searchRes, ok := cash.GetItem(searchHash)
	if ok {
		pm.printMultiSearchResults(searchRes, params.PerPage)
		return
	}

	fmt.Println("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à–µ ‚è≥ –ò—â–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ –≤–æ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö...")
	//fmt.Println("‚è≥ –ò—â–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ –≤–æ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö...")
	ctx := context.Background()
	results, err := pm.concurrentSearchWithTimeout(ctx, params, 10*time.Second)
	if err != nil {
		fmt.Printf("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: %v\n", err)
		return
	}
	//–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à
	cash.AddItemWithTTL(searchHash, results, time.Minute)

	pm.printMultiSearchResults(results, params.PerPage)
}

// concurrentSearchWithTimeout –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –≤–æ –≤—Å–µ—Ö –ø–∞—Ä—Å–µ—Ä–∞—Ö –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
func (pm *ParserManager) concurrentSearchWithTimeout(ctx context.Context, params models.SearchParams, timeout time.Duration) ([]models.SearchResult, error) {
	// —Å–æ–∑–¥–∞—ë–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å —Ç–∞–π–º–∞—É—Ç–æ–º
	ctx, cancel := context.WithTimeout(ctx, timeout)
	defer cancel()

	var wg sync.WaitGroup
	results := make(chan models.SearchResult, len(pm.parsers))

	for _, parser := range pm.parsers {
		wg.Add(1)
		go func(p interfaces.Parser) {
			defer wg.Done()

			// –°–æ–∑–¥–∞–µ–º –∫–∞–Ω–∞–ª –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏ —Å–æ–∑–¥–∞—ë–º –µ—â—ë –æ–¥–Ω—É –≥–æ—Ä—É—Ç–∏–Ω—É, –≥–¥–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏–º –ø–æ–∏—Å–∫
			// 2—è - –≥–æ—Ä—É—Ç–∏–Ω–∞ –Ω—É–∂–Ω–∞, —á—Ç–æ–±—ã –ø–æ—Ç–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å select –∏ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–º–µ–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
			resultChan := make(chan models.SearchResult, 1)

			go func() {
				start := time.Now()
				vacancies, err := p.SearchVacancies(params)
				duration := time.Since(start)

				resultChan <- models.SearchResult{
					ParserName: p.GetName(),
					Vacancies:  vacancies,
					Error:      err,
					Duration:   duration,
				}
			}()

			select {
			case <-ctx.Done():
				// –¢–∞–π–º–∞—É—Ç –∏–ª–∏ –æ—Ç–º–µ–Ω–∞
				results <- models.SearchResult{
					ParserName: p.GetName(),
					Error:      fmt.Errorf("timeout exceeded"),
				}
			case result := <-resultChan:
				results <- result
			}
		}(parser)
	}

	// –≤ —ç—Ç–æ–π –≥–æ—Ä—É—Ç–∏–Ω–µ –¥–æ–∂–∏–¥–∞–µ–º—Å—è –æ–∫–æ–Ω—á–∞–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç –≤—Å–µ—Ö –ø–∞—Ä—Å–µ—Ä–æ–≤ –∏ –∑–∞–∫—Ä—ã–≤–∞–µ–º –∫–∞–Ω–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
	go func() {
		wg.Wait()
		close(results)
	}()

	// –æ–±—å—è–≤–ª—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
	var searchResults []models.SearchResult

	for result := range results {
		searchResults = append(searchResults, result)
	}

	return searchResults, nil
}

// GetAllParsers –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–∞—Ä—Å–µ—Ä–æ–≤
func (pm *ParserManager) GetParserNames() []string {
	names := make([]string, len(pm.parsers))
	for i, parser := range pm.parsers {
		names[i] = parser.GetName()
	}
	return names
}

// –ú–µ—Ç–æ–¥ –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ –∫–æ–Ω—Å–æ–ª—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ (—Å –Ω—É–∂–Ω—ã–º–∏ –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏)
func (pm *ParserManager) printMultiSearchResults(results []models.SearchResult, resultsPerPage int) {
	totalVacancies := 0

	for _, result := range results {
		fmt.Printf("\nüìä %s:\n", result.ParserName)
		fmt.Printf("   ‚è±Ô∏è  –í—Ä–µ–º—è: %v\n", result.Duration)

		if result.Error != nil {
			fmt.Printf("   ‚ùå –û—à–∏–±–∫–∞: %v\n", result.Error)
			continue
		}

		fmt.Printf("   ‚úÖ –ù–∞–π–¥–µ–Ω–æ: %d –≤–∞–∫–∞–Ω—Å–∏–π\n", len(result.Vacancies))
		totalVacancies += len(result.Vacancies)

		// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
		for i, vacancy := range result.Vacancies {
			if i >= resultsPerPage {
				break
			}
			fmt.Printf("      %d. %s - %s, company:%s, URL:[ %s ], ID:%s\n", i+1, vacancy.Job, *vacancy.Salary, vacancy.Company, vacancy.URL, vacancy.ID)
		}

		if len(result.Vacancies) > resultsPerPage {
			fmt.Printf("      ... –∏ –µ—â—ë %d\n", len(result.Vacancies)-resultsPerPage)
		}
	}

	fmt.Printf("\nüéØ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: %d –≤–∞–∫–∞–Ω—Å–∏–π\n", totalVacancies)
}

// —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ö—ç—à –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–∏—Å–∫–∞, —á—Ç–æ–±—ã –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å—ã –ø–æ —ç—Ç–æ–º—É —Ö—ç—à—É
func GenHashFromSearchParam(params models.SearchParams) (string, error) {
	// –£—á–∏—Ç—ã–≤–∞–µ–º –í–°–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤–ª–∏—è—é—Ç –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
	keyData := struct {
		Text    string `json:"text"`
		Area    string `json:"area"`
		PerPage int    `json:"per_page"`
		Page    int    `json:"page"`
		// –î–æ–±–∞–≤—å—Ç–µ –¥—Ä—É–≥–∏–µ –ø–æ–ª—è –∏–∑ SearchParams
	}{
		Text:    params.Text,
		Area:    params.Area,
		PerPage: params.PerPage,
		Page:    params.Page,
	}

	data, err := json.Marshal(keyData)
	if err != nil {
		return "", fmt.Errorf("Error while marshaling of params: %w\n", err)
	}
	hash := sha256.Sum256(data)
	return fmt.Sprintf("%s", hex.EncodeToString(hash[:16])), nil
}
